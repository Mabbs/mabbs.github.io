---
layout: post
title: 近期LLM的部署与应用经历(2)
tags: [LLM, AI, 人工智能]
---

  最近AI发展好快啊～<!--more-->    

# 起因
  自从[上次](/2025/02/22/llm.html)写完文章之后，最近这段时间LLM圈又有了不少更新，感觉很值得试试看。所以这次就来看看这些新东西有什么特别的地方吧。   

# 关于阿里QwQ模型的体验
  前两天阿里的推理模型QwQ模型更新到正式版了，不过其实我也没试过他们的预览版效果怎么样……但按照他们的说法，他们的32b参数的模型水平已经相当于DeepSeek-R1 671b的模型了。如果真是这样，那就太好了，毕竟那个671b参数的模型部署难度还是相当大的，在当时想部署一个能用级别的还是挺烧钱的。但如果这个32b参数的模型能达到相同水平，那就完全没有必要买那么贵的硬件了。像上次买的RTX4090 48GiB显存魔改版可以轻松跑QwQ 32b Q8量化的版本（速度能达到23T/s），就算想跑没有量化的fp16版，也只需要再买一张RTX4090 48GiB就够了，这个成本相比DeepSeek-R1低太多了。   
  所以刚发布的那天我下午就把模型下载下来试了试，随便试了几个问题，答得效果确实不错，我对比了一下DeepSeek-R1，试了试“世界上最长的单词中哪个字母最多”这个问题，两边回答的格式几乎一样，都说的是“硅肺病”的英文，并且都进行了字母数量分析，主要的结论都分析正确了，但是第二多和第三多的字母数量两边说的都不完全正确。另外我还试了试DeepSeek-R1的14b和70b蒸馏版，虽然回答正确了，但是并没有分析具体字母的数量，所以从这一点来看确实是和DeepSeek-R1的水平很相似。不过后来我又让其他人试了试文本分析之类的能力，似乎没能达到他们的预期，另外我还测了测比较宽泛的问题，以及解析文本之类的问题，结果很多问题没能正确回答……所以还是不能和DeepSeek-R1相比较，不过相比DeepSeek-R1各个蒸馏版的水平还是强了不少的，至少没有出现在回答结果中随机输出英文的情况，但是偶尔会出现没有闭合标签“&lt;/think&gt;”的情况，看起来应该不能用于生产环境……要想正经用还是得用完整版的DeepSeek-R1，但毕竟成本问题还是很大啊……所以如果需要考虑成本问题的话用QwQ还是很不错的选择。   
  不过QwQ相比DeepSeek-R1还有一个优势，那就是支持Agent能力，原生支持调用用户提供的函数，像它虽然解析文本的能力不怎么强，但是它可以调用工具来处理，而DeepSeek-R1要想支持就得写提示词，但是毕竟没有专门训练过，不一定能正确使用工具（虽然我没试过😝）。   
  另外说到Agent，好像有个叫“Manus”的产品挺火？但那个我实在没兴趣，一点技术含量都没有，还搞什么邀请码，一看就是买的水军，而且还被人不到一天时间实现了开源版[OpenManus](https://github.com/mannaandpoem/OpenManus)，给人笑掉大牙了🤣。   

# 关于新出的Mac Studio的看法
  搭完整版的DeepSeek-R1即使是使用上次所说的[KTransformers](https://github.com/kvcache-ai/ktransformers)框架也是相当费钱的，最起码也得10万CNY左右。但最近几天苹果出了新的Mac Studio，最高配的M3 Ultra可以选配512GiB的内存，可以轻松跑DeepSeek-R1 671b Q4_K的版本，然后价格最低仅需7.5万CNY。我之前还想着是出M4 Ultra呢……结果出了个M4 Max，不过新的Mac Studio出的速度比我预期的快了好多，我本来以为会在WWDC25的时候出呢……看来是想借DeepSeek-R1大卖一波，当然从这个产品来说确实应该是会大卖的，回头看看能不能搞一个来。不过现在才刚开售，还没人拿到实物呢，也没人实机跑一下，所以先等等最早买到的人跑一波看看，如果效果好的话也许能整一个呢……   

# 关于如何查看MaxKB的完整接口文档
  上一篇文章我说明了一下如何解除MaxKB用户、应用以及知识库的数量限制，后来我发现它还限制了社区版查看完整API文档的能力😅，这个限制给我看的那叫一个大开眼界，它居然还给这个文档整了个硬编码的密码，从来没见过这么搞开源的，具体就是[这一行](https://github.com/1Panel-dev/MaxKB/blob/f1a1c40724ceba108febb416aadb01ccb71c3add/apps/common/init/init_doc.py#L80)。虽然我不知道这里面提到的MD5对应的密码是多少，但是既然是开源代码，我把这句话删了不就行了……不过实际上不太行，因为它使用了Django的国际化功能，直接删掉会影响这个文件的行数，程序会报错。不过可以仔细看一下关于“init_chat_doc”这一行在密码的判断后面加了个“or True”，看来是MaxKB的开发者后来应老板要求放开“chat_doc”的限制，但是又懒得改国际化那边的东西所以加的这个吧🤣，那既然这样，我直接给“init_app_doc”对应的那句话也加个“or True”不就行了，加完之后打开“/doc/”路径，就可以看到MaxKB的完整API文档了，不需要自己手动再去抓包测试了。   
  至于其他的专业版功能我看了一下应该确实是需要用到XPACK包的（不过其实关于修改页面风格的前端开源了，后端在XPACK里，要想用得自己实现接口），开源的这部分最多只能到这里了，估计是这些限制没法单独搞一个包，所以他们就直接在开源代码上做限制😅，看来他们老板也是没眼力啊。   
  其实与其余用MaxKB，不如用[Dify](https://github.com/langgenius/dify)，至少它没有在代码里塞莫名其妙的东西来恶心人，文档也相对更完备，不过它目前还是相当的不成熟，有很多BUG，比如上传知识库显示支持Excel，但是解析的时候会失败，上传知识库如果通过改配置超过15M解析也会失败，还有它的插件很多也是不能用，比如目前阿里云的百炼会报错，退回上个版本就不支持思维链的展示等等……总之不太适合生产使用。   

# 感想
  现在的AI发展确实是快啊，才几天时间又有一堆有意思的发展，应该说现在很多公司都在趁这个机会来发布自己的产品吧，感觉现在也是一个能有很多机会的时刻，不过AI对研究能力的要求也是相当高的，想在这个时间蹭热度也得有相当厉害的能力……像阿里的水平也是相当强的，可惜营销水平不太行😆。只是像我应该也只能看着大公司的百花齐放吧，看看接下来的时间还会不会出现一些有意思的东西。   